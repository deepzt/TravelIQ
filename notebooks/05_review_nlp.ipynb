{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05 - Review NLP (Hotel-Level Summaries)\n",
    "\n",
    "Pipeline:\n",
    "1) Load `reviews.csv` + `offerings.csv`\n",
    "2) Merge (CRITICAL) so each review maps to a hotel\n",
    "3) Clean review text\n",
    "4) Sentiment analysis\n",
    "5) Pros & Cons extraction\n",
    "6) Aggregate at hotel level (API-ready output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import ast\n",
    "import re\n",
    "from collections import Counter, defaultdict\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_DIR = Path('..') / 'data'\n",
    "REVIEWS_CSV = DATA_DIR / 'reviews.csv'\n",
    "OFFERINGS_CSV = DATA_DIR / 'offerings.csv'\n",
    "\n",
    "REVIEWS_CSV.exists(), OFFERINGS_CSV.exists()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load BOTH files (safe for large reviews.csv)\n",
    "`reviews.csv` is large, so we stream it in chunks and aggregate incrementally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4333, 9),\n",
       " ['hotel_class',\n",
       "  'region_id',\n",
       "  'url',\n",
       "  'phone',\n",
       "  'details',\n",
       "  'address',\n",
       "  'type',\n",
       "  'id',\n",
       "  'name'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offerings = pd.read_csv(OFFERINGS_CSV)\n",
    "offerings.shape, offerings.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>offering_id</th>\n",
       "      <th>hotel</th>\n",
       "      <th>city</th>\n",
       "      <th>hotel_class</th>\n",
       "      <th>region_id</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>113317</td>\n",
       "      <td>Casablanca Hotel Times Square</td>\n",
       "      <td>New York City</td>\n",
       "      <td>4.0</td>\n",
       "      <td>60763</td>\n",
       "      <td>http://www.tripadvisor.com/Hotel_Review-g60763...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76049</td>\n",
       "      <td>Four Seasons Hotel Los Angeles at Beverly Hills</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>5.0</td>\n",
       "      <td>32655</td>\n",
       "      <td>http://www.tripadvisor.com/Hotel_Review-g32655...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>99352</td>\n",
       "      <td>Hilton Garden Inn Times Square</td>\n",
       "      <td>New York City</td>\n",
       "      <td>3.5</td>\n",
       "      <td>60763</td>\n",
       "      <td>http://www.tripadvisor.com/Hotel_Review-g60763...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>93589</td>\n",
       "      <td>The Michelangelo Hotel</td>\n",
       "      <td>New York City</td>\n",
       "      <td>4.0</td>\n",
       "      <td>60763</td>\n",
       "      <td>http://www.tripadvisor.com/Hotel_Review-g60763...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>217616</td>\n",
       "      <td>The Muse Hotel New York</td>\n",
       "      <td>New York City</td>\n",
       "      <td>4.0</td>\n",
       "      <td>60763</td>\n",
       "      <td>http://www.tripadvisor.com/Hotel_Review-g60763...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   offering_id                                            hotel  \\\n",
       "0       113317                    Casablanca Hotel Times Square   \n",
       "1        76049  Four Seasons Hotel Los Angeles at Beverly Hills   \n",
       "2        99352                   Hilton Garden Inn Times Square   \n",
       "3        93589                           The Michelangelo Hotel   \n",
       "4       217616                          The Muse Hotel New York   \n",
       "\n",
       "            city  hotel_class  region_id  \\\n",
       "0  New York City          4.0      60763   \n",
       "1    Los Angeles          5.0      32655   \n",
       "2  New York City          3.5      60763   \n",
       "3  New York City          4.0      60763   \n",
       "4  New York City          4.0      60763   \n",
       "\n",
       "                                                 url  \n",
       "0  http://www.tripadvisor.com/Hotel_Review-g60763...  \n",
       "1  http://www.tripadvisor.com/Hotel_Review-g32655...  \n",
       "2  http://www.tripadvisor.com/Hotel_Review-g60763...  \n",
       "3  http://www.tripadvisor.com/Hotel_Review-g60763...  \n",
       "4  http://www.tripadvisor.com/Hotel_Review-g60763...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Minimal hotel info frame for merging\n",
    "hotels = offerings[offerings['type'].eq('hotel')].copy()\n",
    "hotels = hotels.rename(columns={'id': 'offering_id', 'name': 'hotel'})\n",
    "\n",
    "def parse_locality(address_str: str) -> str | None:\n",
    "    if pd.isna(address_str):\n",
    "        return None\n",
    "    try:\n",
    "        d = ast.literal_eval(address_str)\n",
    "        if isinstance(d, dict):\n",
    "            return d.get('locality')\n",
    "    except Exception:\n",
    "        return None\n",
    "    return None\n",
    "\n",
    "hotels['city'] = hotels['address'].apply(parse_locality)\n",
    "hotels = hotels[['offering_id', 'hotel', 'city', 'hotel_class', 'region_id', 'url']]\n",
    "hotels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Merge Reviews with Hotel Info (CRITICAL)\n",
    "We merge on `reviews.offering_id == hotels.offering_id`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Clean Review Text\n",
    "We normalize whitespace, strip junk, and keep human-readable text for downstream sentiment + phrase extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "_WS_RE = re.compile(r'\\s+')\n",
    "_BAD_CHARS_RE = re.compile(r'[^\\w\\s\\.,;:!\\?\"\\'\\-\\(\\)\\/]+', re.UNICODE)\n",
    "\n",
    "\n",
    "def clean_text(text: str | float) -> str:\n",
    "    if text is None or (isinstance(text, float) and np.isnan(text)):\n",
    "        return ''\n",
    "    t = str(text)\n",
    "    t = _BAD_CHARS_RE.sub(' ', t)\n",
    "    t = _WS_RE.sub(' ', t).strip()\n",
    "    return t\n",
    "\n",
    "\n",
    "def tokenize(text: str) -> list[str]:\n",
    "    t = clean_text(text).lower()\n",
    "    toks = re.findall(r\"[a-zA-Z]{2,}\", t)\n",
    "    return toks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Sentiment Analysis (Production-Grade)\n",
    "Primary path: HuggingFace `transformers` sentiment pipeline (if installed).\n",
    "Fallback path: lexicon-based scoring (so the notebook runs even without extra packages)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\blueb\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def try_load_transformer_sentiment():\n",
    "    try:\n",
    "        from transformers import pipeline\n",
    "\n",
    "        return pipeline(\n",
    "            'sentiment-analysis',\n",
    "            model='distilbert-base-uncased-finetuned-sst-2-english',\n",
    "            truncation=True,\n",
    "        )\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "_sent_pipe = try_load_transformer_sentiment()\n",
    "_sent_pipe is not None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9998711347579956, 0.0015205740928649902]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_POS = {\n",
    "    'clean','great','excellent','amazing','awesome','friendly','helpful','comfortable','perfect','nice','love',\n",
    "    'convenient','recommend','best','wonderful','spacious','quiet','beautiful','fantastic','delightful',\n",
    "}\n",
    "_NEG = {\n",
    "    'dirty','bad','terrible','awful','rude','noisy','slow','worst','poor','expensive','smell','broken',\n",
    "    'uncomfortable','disappointed','horrible','problem','bugs','small','crowded','overpriced',\n",
    "}\n",
    "\n",
    "\n",
    "def _fallback_sentiment_score(text: str) -> float:\n",
    "    t = clean_text(text)\n",
    "    if not t:\n",
    "        return 0.5\n",
    "\n",
    "    toks = re.findall(r'[a-zA-Z]{2,}', t.lower())\n",
    "    if not toks:\n",
    "        return 0.5\n",
    "\n",
    "    pos = sum(1 for w in toks if w in _POS)\n",
    "    neg = sum(1 for w in toks if w in _NEG)\n",
    "    raw = (pos - neg) / max(1, pos + neg)\n",
    "    return float(np.clip(0.5 + 0.5 * raw, 0.0, 1.0))\n",
    "\n",
    "\n",
    "def batch_sentiment_scores(texts: list[str], batch_size: int = 64) -> list[float]:\n",
    "    if not texts:\n",
    "        return []\n",
    "\n",
    "    if _sent_pipe is None:\n",
    "        return [_fallback_sentiment_score(t) for t in texts]\n",
    "\n",
    "    scores: list[float] = []\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = [t[:512] for t in texts[i : i + batch_size]]\n",
    "        outs = _sent_pipe(batch)\n",
    "        for out in outs:\n",
    "            label = str(out.get('label', ''))\n",
    "            s = float(out.get('score', 0.5))\n",
    "            if label.upper().startswith('NEG'):\n",
    "                s = 1.0 - s\n",
    "            scores.append(float(s))\n",
    "\n",
    "    return scores\n",
    "\n",
    "\n",
    "batch_sentiment_scores(['Great clean room and friendly staff', 'Slow wifi and dirty bathroom'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Extract Pros & Cons (Differentiator)\n",
    "We split reviews into sentences, score each sentence, then extract frequent bi/tri-gram phrases from positive vs negative sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "_STOP = {\n",
    "    'the','a','an','and','or','but','to','of','in','on','for','with','is','it','this','that','was','were',\n",
    "    'are','be','as','at','by','from','we','i','you','they','our','my','your','their','me','us','him','her',\n",
    "    'very','really','so','too','just','also','not','no','yes','can','could','would','should','will','have','had',\n",
    "}\n",
    "\n",
    "# Keyword dictionary for fast pros/cons without sentence-level BERT\n",
    "PRO_KEYWORDS = {\n",
    "    'clean': ['clean', 'spotless'],\n",
    "    'staff': ['friendly', 'helpful', 'staff', 'service'],\n",
    "    'location': ['location', 'close', 'convenient', 'walk'],\n",
    "    'room': ['room', 'rooms', 'spacious', 'comfortable', 'bed', 'beds'],\n",
    "    'view': ['view'],\n",
    "    'food': ['breakfast', 'food', 'restaurant'],\n",
    "    'wifi': ['wifi', 'wi-fi', 'internet'],\n",
    "}\n",
    "CON_KEYWORDS = {\n",
    "    'wifi': ['wifi', 'wi-fi', 'internet', 'slow'],\n",
    "    'noise': ['noisy', 'noise', 'loud'],\n",
    "    'cleanliness': ['dirty', 'smell', 'bugs'],\n",
    "    'price': ['expensive', 'overpriced'],\n",
    "    'room': ['small', 'broken'],\n",
    "}\n",
    "\n",
    "\n",
    "def _contains_any(tokens_set: set[str], keywords: list[str]) -> bool:\n",
    "    return any(k.replace('-', '').lower() in tokens_set or k.lower() in tokens_set for k in keywords)\n",
    "\n",
    "\n",
    "def extract_keyword_phrases(text: str, sentiment: float, pos_th: float = 0.65, neg_th: float = 0.35) -> tuple[list[str], list[str]]:\n",
    "    toks = tokenize(text)\n",
    "    toks_set = set(toks)\n",
    "\n",
    "    pros: list[str] = []\n",
    "    cons: list[str] = []\n",
    "\n",
    "    if sentiment >= pos_th:\n",
    "        for label, kws in PRO_KEYWORDS.items():\n",
    "            if _contains_any(toks_set, kws):\n",
    "                # output a readable phrase (API-friendly)\n",
    "                if label == 'staff':\n",
    "                    pros.append('friendly staff')\n",
    "                elif label == 'room':\n",
    "                    pros.append('clean rooms')\n",
    "                elif label == 'wifi':\n",
    "                    pros.append('good wifi')\n",
    "                else:\n",
    "                    pros.append(label)\n",
    "\n",
    "    if sentiment <= neg_th:\n",
    "        for label, kws in CON_KEYWORDS.items():\n",
    "            if _contains_any(toks_set, kws):\n",
    "                if label == 'wifi':\n",
    "                    cons.append('slow wifi')\n",
    "                elif label == 'noise':\n",
    "                    cons.append('noisy rooms')\n",
    "                elif label == 'price':\n",
    "                    cons.append('expensive')\n",
    "                else:\n",
    "                    cons.append(label)\n",
    "\n",
    "    return pros, cons\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Aggregate at HOTEL Level (API-ready)\n",
    "We stream reviews in chunks and build per-hotel aggregates: avg rating, avg sentiment, pros/cons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_overall_rating(ratings_str: str | float) -> float | None:\n",
    "    if ratings_str is None or (isinstance(ratings_str, float) and np.isnan(ratings_str)):\n",
    "        return None\n",
    "    try:\n",
    "        d = ast.literal_eval(ratings_str)\n",
    "        if isinstance(d, dict) and 'overall' in d:\n",
    "            return float(d['overall'])\n",
    "    except Exception:\n",
    "        return None\n",
    "    return None\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class HotelAgg:\n",
    "    rating_sum: float = 0.0\n",
    "    rating_n: int = 0\n",
    "    sent_sum: float = 0.0\n",
    "    sent_n: int = 0\n",
    "    pros: Counter = None\n",
    "    cons: Counter = None\n",
    "\n",
    "    def __post_init__(self):\n",
    "        if self.pros is None:\n",
    "            self.pros = Counter()\n",
    "        if self.cons is None:\n",
    "            self.cons = Counter()\n",
    "\n",
    "\n",
    "def update_agg(agg: HotelAgg, review_text: str, overall_rating: float | None, sentiment: float):\n",
    "    agg.sent_sum += float(sentiment)\n",
    "    agg.sent_n += 1\n",
    "\n",
    "    if overall_rating is not None:\n",
    "        agg.rating_sum += float(overall_rating)\n",
    "        agg.rating_n += 1\n",
    "\n",
    "    pros, cons = extract_keyword_phrases(review_text, sentiment)\n",
    "    agg.pros.update(pros)\n",
    "    agg.cons.update(cons)\n",
    "\n",
    "\n",
    "def top_k(counter: Counter, k: int = 6) -> list[str]:\n",
    "    items = [p for p, _ in counter.most_common(k)]\n",
    "    return items\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cache not found. Building cache at: ..\\data\\reviews_enriched_cached.csv.gz\n",
      "Using CHUNKSIZE=25,000 MAX_REVIEWS=50,000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk 1: raw=25,000 kept=25,000 | processed=25,000/50,000 | chunk_time=2352.6s | rate=11 reviews/s | ETA=39.2 min\n",
      "chunk 2: raw=25,000 kept=25,000 | processed=50,000/50,000 | chunk_time=2176.2s | rate=11 reviews/s | ETA=0.0 min\n",
      "Reached MAX_REVIEWS cap. Stopping early.\n",
      "Concatenating cached dataset...\n",
      "Writing cache to ..\\data\\reviews_enriched_cached.csv.gz (gzip)...\n",
      "Cache saved. cached.shape=(50000, 6)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "CHUNKSIZE = 25_000\n",
    "MAX_REVIEWS = 50_000  # smaller sample for iteration; increase only for final offline run\n",
    "\n",
    "CACHE_PATH = DATA_DIR / 'reviews_enriched_cached.csv.gz'\n",
    "\n",
    "hotel_index = hotels.set_index('offering_id')[['hotel','city']].to_dict(orient='index')\n",
    "\n",
    "use_cols = ['offering_id', 'ratings', 'title', 'text']\n",
    "\n",
    "if not CACHE_PATH.exists():\n",
    "    print(f'Cache not found. Building cache at: {CACHE_PATH}', flush=True)\n",
    "    print(f'Using CHUNKSIZE={CHUNKSIZE:,} MAX_REVIEWS={MAX_REVIEWS:,}', flush=True)\n",
    "\n",
    "    processed = 0\n",
    "    out_parts = []\n",
    "    chunk_i = 0\n",
    "    t_start = time.time()\n",
    "\n",
    "    for chunk in pd.read_csv(REVIEWS_CSV, usecols=use_cols, chunksize=CHUNKSIZE):\n",
    "        chunk_i += 1\n",
    "        t_chunk = time.time()\n",
    "        raw_n = len(chunk)\n",
    "\n",
    "        chunk = chunk[chunk['offering_id'].isin(hotel_index.keys())]\n",
    "        kept_n = len(chunk)\n",
    "        if kept_n == 0:\n",
    "            print(f'chunk {chunk_i}: raw={raw_n:,} kept=0 (filtered) | processed={processed:,}', flush=True)\n",
    "            continue\n",
    "\n",
    "        chunk = chunk.merge(hotels, on='offering_id', how='left')\n",
    "        chunk['review_text'] = (chunk['title'].fillna('') + ' ' + chunk['text'].fillna('')).map(clean_text)\n",
    "        chunk['overall_rating'] = chunk['ratings'].map(parse_overall_rating)\n",
    "\n",
    "        texts = chunk['review_text'].tolist()\n",
    "        chunk['sentiment_score'] = batch_sentiment_scores(texts, batch_size=64)\n",
    "\n",
    "        out_parts.append(chunk[['offering_id','hotel','city','overall_rating','sentiment_score','review_text']])\n",
    "\n",
    "        processed += kept_n\n",
    "\n",
    "        elapsed = time.time() - t_start\n",
    "        rate = processed / max(1e-6, elapsed)\n",
    "        remaining = max(0, MAX_REVIEWS - processed)\n",
    "        eta_sec = remaining / max(1e-6, rate)\n",
    "        chunk_sec = time.time() - t_chunk\n",
    "\n",
    "        print(\n",
    "            f\"chunk {chunk_i}: raw={raw_n:,} kept={kept_n:,} | processed={processed:,}/{MAX_REVIEWS:,} \"\n",
    "            f\"| chunk_time={chunk_sec:.1f}s | rate={rate:,.0f} reviews/s | ETA={eta_sec/60:.1f} min\",\n",
    "            flush=True,\n",
    "        )\n",
    "\n",
    "        if processed >= MAX_REVIEWS:\n",
    "            print('Reached MAX_REVIEWS cap. Stopping early.', flush=True)\n",
    "            break\n",
    "\n",
    "    print('Concatenating cached dataset...', flush=True)\n",
    "    cached = pd.concat(out_parts, ignore_index=True)\n",
    "    print(f'Writing cache to {CACHE_PATH} (gzip)...', flush=True)\n",
    "    cached.to_csv(CACHE_PATH, index=False, compression='gzip')\n",
    "    print(f'Cache saved. cached.shape={cached.shape}', flush=True)\n",
    "\n",
    "    cached.shape\n",
    "else:\n",
    "    print(f'Cache found: {CACHE_PATH}', flush=True)\n",
    "    t0 = time.time()\n",
    "    cached = pd.read_csv(CACHE_PATH)\n",
    "    print(f'Loaded cache in {time.time()-t0:.2f}s | cached.shape={cached.shape}', flush=True)\n",
    "    cached.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>offering_id</th>\n",
       "      <th>hotel</th>\n",
       "      <th>city</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>pros</th>\n",
       "      <th>cons</th>\n",
       "      <th>n_reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>93338</td>\n",
       "      <td>Hotel Beacon</td>\n",
       "      <td>New York City</td>\n",
       "      <td>4.502400</td>\n",
       "      <td>0.872416</td>\n",
       "      <td>[clean rooms, location, friendly staff, clean,...</td>\n",
       "      <td>[room, slow wifi, noisy rooms, cleanliness, ex...</td>\n",
       "      <td>1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1456560</td>\n",
       "      <td>Eventi - a Kimpton Hotel</td>\n",
       "      <td>New York City</td>\n",
       "      <td>4.553327</td>\n",
       "      <td>0.846388</td>\n",
       "      <td>[clean rooms, friendly staff, location, clean,...</td>\n",
       "      <td>[room, slow wifi, noisy rooms, expensive, clea...</td>\n",
       "      <td>1097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>93396</td>\n",
       "      <td>The Iroquois</td>\n",
       "      <td>New York City</td>\n",
       "      <td>4.473983</td>\n",
       "      <td>0.834070</td>\n",
       "      <td>[friendly staff, clean rooms, location, clean,...</td>\n",
       "      <td>[room, slow wifi, noisy rooms, expensive, clea...</td>\n",
       "      <td>1057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>290978</td>\n",
       "      <td>Hotel St. James</td>\n",
       "      <td>New York City</td>\n",
       "      <td>3.474747</td>\n",
       "      <td>0.534504</td>\n",
       "      <td>[clean rooms, location, clean, friendly staff,...</td>\n",
       "      <td>[slow wifi, room, noisy rooms, cleanliness, ex...</td>\n",
       "      <td>990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>112066</td>\n",
       "      <td>W New York</td>\n",
       "      <td>New York City</td>\n",
       "      <td>3.760204</td>\n",
       "      <td>0.679850</td>\n",
       "      <td>[clean rooms, friendly staff, location, clean,...</td>\n",
       "      <td>[room, noisy rooms, expensive, slow wifi, clea...</td>\n",
       "      <td>980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>93517</td>\n",
       "      <td>Paramount Hotel Times Square New York</td>\n",
       "      <td>New York City</td>\n",
       "      <td>3.668041</td>\n",
       "      <td>0.676281</td>\n",
       "      <td>[clean rooms, location, friendly staff, clean,...</td>\n",
       "      <td>[room, noisy rooms, slow wifi, cleanliness, ex...</td>\n",
       "      <td>970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>93345</td>\n",
       "      <td>Skyline Hotel</td>\n",
       "      <td>New York City</td>\n",
       "      <td>3.603333</td>\n",
       "      <td>0.672377</td>\n",
       "      <td>[clean rooms, location, friendly staff, clean,...</td>\n",
       "      <td>[noisy rooms, slow wifi, room, cleanliness, ex...</td>\n",
       "      <td>900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>93333</td>\n",
       "      <td>Wolcott Hotel</td>\n",
       "      <td>New York City</td>\n",
       "      <td>3.584029</td>\n",
       "      <td>0.586469</td>\n",
       "      <td>[clean rooms, location, friendly staff, clean,...</td>\n",
       "      <td>[slow wifi, room, noisy rooms, cleanliness, ex...</td>\n",
       "      <td>839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1762573</td>\n",
       "      <td>Andaz 5th Avenue</td>\n",
       "      <td>New York City</td>\n",
       "      <td>4.583673</td>\n",
       "      <td>0.805440</td>\n",
       "      <td>[clean rooms, friendly staff, location, food, ...</td>\n",
       "      <td>[slow wifi, room, noisy rooms, expensive, clea...</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>93526</td>\n",
       "      <td>the Lexington</td>\n",
       "      <td>New York City</td>\n",
       "      <td>3.381974</td>\n",
       "      <td>0.607839</td>\n",
       "      <td>[clean rooms, location, friendly staff, clean,...</td>\n",
       "      <td>[room, noisy rooms, cleanliness, slow wifi, ex...</td>\n",
       "      <td>699</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     offering_id                                  hotel           city  \\\n",
       "0          93338                           Hotel Beacon  New York City   \n",
       "4        1456560               Eventi - a Kimpton Hotel  New York City   \n",
       "5          93396                           The Iroquois  New York City   \n",
       "418       290978                        Hotel St. James  New York City   \n",
       "412       112066                             W New York  New York City   \n",
       "417        93517  Paramount Hotel Times Square New York  New York City   \n",
       "415        93345                          Skyline Hotel  New York City   \n",
       "416        93333                          Wolcott Hotel  New York City   \n",
       "1        1762573                       Andaz 5th Avenue  New York City   \n",
       "432        93526                          the Lexington  New York City   \n",
       "\n",
       "     avg_rating  sentiment_score  \\\n",
       "0      4.502400         0.872416   \n",
       "4      4.553327         0.846388   \n",
       "5      4.473983         0.834070   \n",
       "418    3.474747         0.534504   \n",
       "412    3.760204         0.679850   \n",
       "417    3.668041         0.676281   \n",
       "415    3.603333         0.672377   \n",
       "416    3.584029         0.586469   \n",
       "1      4.583673         0.805440   \n",
       "432    3.381974         0.607839   \n",
       "\n",
       "                                                  pros  \\\n",
       "0    [clean rooms, location, friendly staff, clean,...   \n",
       "4    [clean rooms, friendly staff, location, clean,...   \n",
       "5    [friendly staff, clean rooms, location, clean,...   \n",
       "418  [clean rooms, location, clean, friendly staff,...   \n",
       "412  [clean rooms, friendly staff, location, clean,...   \n",
       "417  [clean rooms, location, friendly staff, clean,...   \n",
       "415  [clean rooms, location, friendly staff, clean,...   \n",
       "416  [clean rooms, location, friendly staff, clean,...   \n",
       "1    [clean rooms, friendly staff, location, food, ...   \n",
       "432  [clean rooms, location, friendly staff, clean,...   \n",
       "\n",
       "                                                  cons  n_reviews  \n",
       "0    [room, slow wifi, noisy rooms, cleanliness, ex...       1250  \n",
       "4    [room, slow wifi, noisy rooms, expensive, clea...       1097  \n",
       "5    [room, slow wifi, noisy rooms, expensive, clea...       1057  \n",
       "418  [slow wifi, room, noisy rooms, cleanliness, ex...        990  \n",
       "412  [room, noisy rooms, expensive, slow wifi, clea...        980  \n",
       "417  [room, noisy rooms, slow wifi, cleanliness, ex...        970  \n",
       "415  [noisy rooms, slow wifi, room, cleanliness, ex...        900  \n",
       "416  [slow wifi, room, noisy rooms, cleanliness, ex...        839  \n",
       "1    [slow wifi, room, noisy rooms, expensive, clea...        735  \n",
       "432  [room, noisy rooms, cleanliness, slow wifi, ex...        699  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggs: dict[int, HotelAgg] = {}\n",
    "\n",
    "for row in cached.itertuples(index=False):\n",
    "    oid = int(row.offering_id)\n",
    "    agg = aggs.get(oid)\n",
    "    if agg is None:\n",
    "        agg = HotelAgg()\n",
    "        aggs[oid] = agg\n",
    "\n",
    "    update_agg(\n",
    "        agg,\n",
    "        review_text=str(row.review_text),\n",
    "        overall_rating=None if pd.isna(row.overall_rating) else float(row.overall_rating),\n",
    "        sentiment=float(row.sentiment_score),\n",
    "    )\n",
    "\n",
    "rows = []\n",
    "for oid, agg in aggs.items():\n",
    "    meta = hotel_index.get(oid, {})\n",
    "    avg_rating = (agg.rating_sum / agg.rating_n) if agg.rating_n else None\n",
    "    sent = (agg.sent_sum / agg.sent_n) if agg.sent_n else None\n",
    "    rows.append({\n",
    "        'offering_id': oid,\n",
    "        'hotel': meta.get('hotel'),\n",
    "        'city': meta.get('city'),\n",
    "        'avg_rating': None if avg_rating is None else float(avg_rating),\n",
    "        'sentiment_score': None if sent is None else float(sent),\n",
    "        'pros': top_k(agg.pros, k=6),\n",
    "        'cons': top_k(agg.cons, k=6),\n",
    "        'n_reviews': int(agg.sent_n),\n",
    "    })\n",
    "\n",
    "hotel_summary = pd.DataFrame(rows)\n",
    "hotel_summary = hotel_summary.sort_values(['n_reviews','sentiment_score'], ascending=[False, False])\n",
    "hotel_summary.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'offering_id': 93338,\n",
       " 'hotel': 'Hotel Beacon',\n",
       " 'city': 'New York City',\n",
       " 'avg_rating': 4.5024,\n",
       " 'sentiment_score': 0.8724156901836395,\n",
       " 'pros': ['clean rooms',\n",
       "  'location',\n",
       "  'friendly staff',\n",
       "  'clean',\n",
       "  'food',\n",
       "  'view'],\n",
       " 'cons': ['room', 'slow wifi', 'noisy rooms', 'cleanliness', 'expensive'],\n",
       " 'n_reviews': 1250}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = hotel_summary.dropna(subset=['hotel']).iloc[0].to_dict()\n",
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adbbe01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Persist hotel-level summaries for reuse in recommendation / API\n",
    "SUMMARY_CSV = DATA_DIR / 'hotel_review_summaries.csv'\n",
    "SUMMARY_JSON = DATA_DIR / 'hotel_review_summaries.json'\n",
    "\n",
    "hotel_summary.to_csv(SUMMARY_CSV, index=False)\n",
    "hotel_summary.to_json(SUMMARY_JSON, orient='records', indent=2)\n",
    "\n",
    "str(SUMMARY_CSV), str(SUMMARY_JSON)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
